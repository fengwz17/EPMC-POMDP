// POMDP model
// UAV collision avoidance
// discrete states
// test
// feng wz

// state space (value of variable "(x, y)")
// s = (x1, y1, x2, y2)
// (x1, y1) is the position of own aircraft
// (x2, y2) is the position of intruder
//  -10 <= x <= 10
// 0 <= y <= 30
// (0, 30) is the target

pomdp

const int detectRange = 10 * 10;
const int NMAC = 3 * 3;

// can observe the direction of intruder relative to own aircraft.
observables
	o : [0.. 2] init 0;
endobservables

// assume the heading of own aircraft is always in the positive y-axis direction
// o = 1: Left, (x2 - x1)^2 + (y2 - y1)^2 <= detectRange * detectRange & x2 <= x1
// o = 2: Right, (x2 - x1)^2 + (y2 - y1)^2 <= detectRange * detectRange & x2 > x1
// o = 0: No-detection, (x2 - x1)^2 + (y2 - y1)^2 > detectRange * detectRange

// intruder
// [own action]: the action means own aircraft's action, the intruder and own aircraft move at the same time
//      the intruder randomly takes an action from "go ahead", "turn left" and "turn right"
//      own aircraft takes action as  [own action]
// Markov chain: I think the intruder's transition is Markov chain because actually there is not "actions" for intruder. 
module intruder

	x2 : [-10..10] init 0;
	y2 : [0.. 30] init 15; 
	// o : [0.. 2] init 0;

	[turnLeft] x2 = -10 & y2 = 0 -> (x2' = x2 + 1);
	[turnLeft] x2 = -10 & y2 > 0 -> 1/2 : (x2' = x2 + 1) + 1/2 : (y2' = y2 - 1);
	[turnRight] x2 = -10 & y2 = 0 -> (x2' = x2 + 1);
	[turnRight] x2 = -10 & y2 > 0 -> 1/2 : (x2' = x2 + 1) + 1/2 : (y2' = y2 - 1);
	[goAhead] x2 = -10 & y2 = 0 -> (x2' = x2 + 1);
	[goAhead] x2 = -10 & y2 = 0 -> 1/2 : (x2' = x2 + 1) + 1/2 : (y2' = y2 - 1);

	[turnLeft] -10 < x2 < 10 & y2 = 0 -> 1/2 : (x2' = x2 - 1) + 1/2 : (x2' = x2 + 1);
	[turnLeft] -10 < x2 < 10 & y2 > 0 -> 1/3 : (x2' = x2 - 1) + 1/3 : (x2' = x2 + 1) + 1/3 : (y2' = y2 - 1);
	[turnRight] -10 < x2 < 10 & y2 = 0 -> 1/2 : (x2' = x2 - 1) + 1/2 : (x2' = x2 + 1);
	[turnRight] -10 < x2 < 10 & y2 > 0 -> 1/3 : (x2' = x2 - 1) + 1/3 : (x2' = x2 + 1) + 1/3 : (y2' = y2 - 1);
	[goAhead] -10 < x2 < 10 & y2 = 0 -> 1/2 : (x2' = x2 - 1) + 1/2 : (x2' = x2 + 1);
	[goAhead] -10 < x2 < 10 & y2 > 0 -> 1/3 : (x2' = x2 - 1) + 1/3 : (x2' = x2 + 1) + 1/3 : (y2' = y2 - 1);

	[turnLeft] x2 = 10 & y2 = 0 -> (x2' = x2 - 1);
	[turnLeft] x2 = 10 & y2 > 0 -> 1/2 : (x2' = x2 - 1) + 1/2 : (y2' = y2 - 1);
	[turnRight] x2 = 10 & y2 = 0 -> (x2' = x2 - 1);
	[turnRight] x2 = 10 & y2 > 0 -> 1/2 : (x2' = x2 - 1) + 1/2 : (y2' = y2 - 1);
	[goAhead] x2 = 10 & y2 = 0 -> (x2' = x2 - 1);
	[goAhead] x2 = 10 & y2 > 0 -> 1/2 : (x2' = x2 - 1) + 1/2 : (y2' = y2 - 1);
	
endmodule

// own aircraft
// [action] curr state -> next state distribution & observation distribution
// [action] guard -> prob_state_1 : ( next_state_1 & (prob_observ_1 : next_observ_1 + ... + prob_observ_n : next_observ_n))
//  + ... + prob_state_m : (next_state_m & (prob_observ_1 : next_observ_1 + ... + prob_observ_n : next_observ_n));
module own

	x1 : [-10.. 10] init 0;
	y1 : [0.. 30] init 0;
	o : [0.. 2] init 0;

	formula disLeft = (x2 - (x1 - 1))^2 + (y2 - y1)^2;
	formula disRight = (x2 - (x1 + 1))^2 + (y2 - y1)^2;
	formula disGoAhead = (x2 - x1)^2 + (y2 - (y1 + 1))^2;

	// moving: turn left, turn right and go ahead
	// state transition probablity: Pr((x1' = x1 -1, y1' = y1) | (x1, y1), turnLeft) = 1, others are the same;
	// observable probablity: Pr(left | x2 <= x1 & dis <= detectRange) = 0.8;
	// observation matrix:
	// --------------- Right ------ Left ------ No-detection ------------
	//  x2 <= x1        0.8                0.1                    0.1
	//  x2 > x1         0.1                0.8                    0.1
	// dis > 100        0.1                0.1                    0.8

	// turn left and observe left, right, no-detection
	[turnLeft] -10 < x1 <= 10 & disLeft <= detectRange & x2 <= x1 - 1 ->  1 : (x1' = x1 - 1) & (y1' = y1) & (0.8 : (o' = 1) + 0.1 : (o' = 2) + 0.1 : (o' = 0));
	[turnLeft] -10 < x1 <= 10 & disLeft <= detectRange & x2 > x1 - 1 -> 1 : (x1' = x1 - 1) & (y1' = y1) & (0.1 : (o' = 1) + 0.8 : (o' = 2) + 0.1 : (o' = 0));
	[turnLeft] -10 < x1 <= 10 & disLeft > detectRange -> 1: (x1' = x1 - 1) & (y1' = y1) & (0.1 : (o' = 1) + 0.1 : (o' = 2) + 0.8 : (o' = 0));

	// turn right
	[turnRight] -10 <= x1 < 10 & disRight <= detectRange & x2 <= x1 -> 1: (x1' = x1 + 1) & (y1' = y1) & (0.8 : (o' = 1) + 0.1 : (o' = 2) + 0.1 : (o' = 0));
	[turnRight] -10 <= x1 < 10 & disRight <= detectRange & x2 > x1 -> 1: (x1' = x1 + 1) & (y1' = y1) & (0.1 : (o' = 1) + 0.8 : (o' = 2) + 0.1 : (o' = 0));
	[turnRight] -10 <= x1 < 10 & disRight > detectRange -> 1: (x1' = x1 + 1) & (y1' = y1) & (0.1 : (o' = 1) + 0.1 : (o' = 2) + 0.8 : (o' = 0));

	// goAhead
	[goAhead] -10 <= x1 < 10 & disGoAhead <= detectRange & x2 <= x1 -> 1: (x1' = x1) & (y1' = y1 + 1) & (0.8 : (o' = 1) + 0.1 : (o' = 2) + 0.1 : (o' = 0));
	[goAhead] -10 <= x1 < 10 & disGoAhead <= detectRange & x2 > x1 -> 1: (x1' = x1) & (y1' = y1 + 1) & (0.1 : (o' = 1) + 0.8 : (o' = 2) + 0.1 : (o' = 0));
	[goAhead] -10 <= x1 < 10 & disGoAhead > detectRange -> 1: (x1' = x1) & (y1' = y1 + 1) & (0.1 : (o' = 1) + 0.1 : (o' = 2) + 0.8 : (o' = 0));
																												

	// reach the target
	[done] x1 = 0 & y1 = 30 -> true;

endmodule

	
endmodule

// reward 
// [action] guard : reward;
rewards

	(x1 - x2)^2 + (y1 - y2)^2 <= NMAC : -1000000;

	// [done] true : 1000; 
	x1 = 0 & y1 = 30 : 1000;

	[turnLeft]  !(x1 = 0 & y1 = 30) : -1;
	[turnRight]  !(x1 = 0 & y1 = 30) : -1;
	[goAhead] !(x1 = 0 & y1 = 30) : 0;  

endrewards