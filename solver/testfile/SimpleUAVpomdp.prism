// POMDP model
// UAV collision avoidance
// discrete states
// test
// feng wz

// state space (value of variable "(x, y)")
// s = (x1, y1, x2, y2)
// (x1, y1) is the position of own aircraft
// (x2, y2) is the position of intruder
//  -1 <= x <= 1
// 0 <= y <= 3
// (0, 3) is the target

pomdp

const int detectRange = 3 * 3;
const int NMAC = 1 * 1;

formula disLeft = pow((x2 - (x1 - 1)),2) + pow((y2 - y1),2);
formula disRight = pow((x2 - (x1 + 1)),2) + pow((y2 - y1),2);
formula disGoAhead = pow((x2 - x1),2) + pow((y2 - (y1 + 1)),2);

// can observe the direction of intruder relative to own aircraft.
observables
	o : [0.. 2];
endobservables

// assume the heading of own aircraft is always in the positive y-axis direction
// o = 1: Left, (x2 - x1)^2 + (y2 - y1)^2 <= detectRange * detectRange & x2 <= x1
// o = 2: Right, (x2 - x1)^2 + (y2 - y1)^2 <= detectRange * detectRange & x2 > x1
// o = 0: No-detection, (x2 - x1)^2 + (y2 - y1)^2 > detectRange * detectRange

// intruder
// [own action]: the action means own aircraft's action, the intruder and own aircraft move at the same time
//      the intruder randomly takes an action from "go ahead", "turn left" and "turn right"
//      own aircraft takes action as  [own action]
// Markov chain: I think the intruder's transition is Markov chain because actually there is not "actions" for intruder. 
module intruder

	x2 : [-1..1] init 0;
	y2 : [0.. 3] init 15; 
	// o : [0.. 2] init 0;

	[turnLeft] x2 = -1 & y2 = 0 -> (x2' = x2 + 1);
	[turnRight] x2 = -1 & y2 = 0 -> (x2' = x2 + 1);
	[goAhead] x2 = -1 & y2 = 0 -> (x2' = x2 + 1);

	[turnLeft] x2 = -1 & y2 > 0 -> 1/2 : (x2' = x2 + 1) + 1/2 : (y2' = y2 - 1);
	[turnRight] x2 = -1 & y2 > 0 -> 1/2 : (x2' = x2 + 1) + 1/2 : (y2' = y2 - 1);
	[goAhead] x2 = -1 & y2 > 0 -> 1/2 : (x2' = x2 + 1) + 1/2 : (y2' = y2 - 1);

	[turnLeft] x2 > -1 & x2 < 1 & y2 = 0 -> 1/2 : (x2' = x2 - 1) + 1/2 : (x2' = x2 + 1);
	[turnRight] x2 > -1 & x2 < 1 & y2 = 0 -> 1/2 : (x2' = x2 - 1) + 1/2 : (x2' = x2 + 1);
	[goAhead] x2 > -1 & x2 < 1 & y2 = 0 -> 1/2 : (x2' = x2 - 1) + 1/2 : (x2' = x2 + 1);

	[turnLeft] x2 > -1 & x2 < 1 & y2 > 0 -> 1/3 : (x2' = x2 - 1) + 1/3 : (x2' = x2 + 1) + 1/3 : (y2' = y2 - 1);
	[turnRight] x2 > -1 & x2 < 1 & y2 > 0 -> 1/3 : (x2' = x2 - 1) + 1/3 : (x2' = x2 + 1) + 1/3 : (y2' = y2 - 1);
	[goAhead] x2 > -1 & x2 < 1 & y2 > 0 -> 1/3 : (x2' = x2 - 1) + 1/3 : (x2' = x2 + 1) + 1/3 : (y2' = y2 - 1);

	[turnLeft] x2 = 1 & y2 = 0 -> (x2' = x2 - 1);
	[turnRight] x2 = 1 & y2 = 0 -> (x2' = x2 - 1);
	[goAhead] x2 = 1 & y2 = 0 -> (x2' = x2 - 1);

	[turnLeft] x2 = 1 & y2 > 0 -> 1/2 : (x2' = x2 - 1) + 1/2 : (y2' = y2 - 1);
	[turnRight] x2 = 1 & y2 > 0 -> 1/2 : (x2' = x2 - 1) + 1/2 : (y2' = y2 - 1);
	[goAhead] x2 = 1 & y2 > 0 -> 1/2 : (x2' = x2 - 1) + 1/2 : (y2' = y2 - 1);
	
endmodule

// own aircraft
// [action] curr state -> next state distribution & observation distribution
// [action] guard -> prob_state_1 : ( next_state_1 & (prob_observ_1 : next_observ_1 + ... + prob_observ_n : next_observ_n))
//  + ... + prob_state_m : (next_state_m & (prob_observ_1 : next_observ_1 + ... + prob_observ_n : next_observ_n));
module own

	x1 : [-1.. 1] init 0;
	y1 : [0.. 3] init 0;
	// o : [0.. 2] init 0;

	

	// moving: turn left, turn right and go ahead
	// state transition probablity: Pr((x1' = x1 -1, y1' = y1) | (x1, y1), turnLeft) = 1, others are the same;
	// observable probablity: Pr(left | x2 <= x1 & dis <= detectRange) = 0.8;
	// observation matrix:
	// --------------- Right ------ Left ------ No-detection ------------
	//  x2 <= x1        0.8                0.1                    0.1
	//  x2 > x1         0.1                0.8                    0.1
	// dis > 100        0.1                0.1                    0.8

	// turn left and observe left, right, no-detection
	[turnLeft] x1 > -1 & disLeft <= detectRange & x2 <= x1 - 1 ->  1 : (x1' = x1 - 1) & (y1' = y1) {0.8 : (o' = 1) + 0.1 : (o' = 2) + 0.1 : (o' = 0)};
	[turnLeft] x1 > -1 & disLeft <= detectRange & x2 > x1 - 1 -> 1 : (x1' = x1 - 1) & (y1' = y1) {0.1 : (o' = 1) + 0.8 : (o' = 2) + 0.1 : (o' = 0)};
	[turnLeft] x1 > -1 & disLeft > detectRange -> 1: (x1' = x1 - 1) & (y1' = y1) {0.1 : (o' = 1) + 0.1 : (o' = 2) + 0.8 : (o' = 0)};

	// turn right
	[turnRight] x1 < 1 & disRight <= detectRange & x2 <= x1 -> 1: (x1' = x1 + 1) & (y1' = y1) {0.8 : (o' = 1) + 0.1 : (o' = 2) + 0.1 : (o' = 0)};
	[turnRight] x1 < 1 & disRight <= detectRange & x2 > x1 -> 1: (x1' = x1 + 1) & (y1' = y1) {0.1 : (o' = 1) + 0.8 : (o' = 2) + 0.1 : (o' = 0)};
	[turnRight] x1 < 1 & disRight > detectRange -> 1: (x1' = x1 + 1) & (y1' = y1) {0.1 : (o' = 1) + 0.1 : (o' = 2) + 0.8 : (o' = 0)};

	// goAhead
	[goAhead] y1 < 3 & disGoAhead <= detectRange & x2 <= x1 -> 1: (x1' = x1) & (y1' = y1 + 1) {0.8 : (o' = 1) + 0.1 : (o' = 2) + 0.1 : (o' = 0)};
	[goAhead] y1 < 3 & disGoAhead <= detectRange & x2 > x1 -> 1: (x1' = x1) & (y1' = y1 + 1) {0.1 : (o' = 1) + 0.8 : (o' = 2) + 0.1 : (o' = 0)};
	[goAhead] y1 < 3 & disGoAhead > detectRange -> 1: (x1' = x1) & (y1' = y1 + 1) {0.1 : (o' = 1) + 0.1 : (o' = 2) + 0.8 : (o' = 0)};
																												

	// reach the target
	[done] x1 = 0 & y1 = 3 -> true;

endmodule

// reward 
// [action] guard : reward;
rewards

	pow((x1 - x2),2) + pow((y1 - y2),2) <= NMAC : -1000000;

	// [done] true : 1000; 
	x1 = 0 & y1 = 3 : 1000;

	[turnLeft]  !(x1 = 0 & y1 = 3) : -1;
	[turnRight]  !(x1 = 0 & y1 = 3) : -1;
	[goAhead] !(x1 = 0 & y1 = 3) : 0;  

endrewards




